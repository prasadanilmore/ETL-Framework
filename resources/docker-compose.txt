version: '3'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.0.0
    environment:
      ZOOKEEPER_CLIENT_PORT: "2181"
      ZOOKEEPER_TICK_TIME: "2000"
    ports:
      - "2181:2181"

  kafka:
    image: confluentinc/cp-kafka:7.0.0
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: "1"

  spark:
    image: bitnami/spark:latest
    ports:
      - "4040:4040"
    depends_on:
      - kafka
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_URL=spark://spark:7077
    command: bin/spark-class org.apache.spark.deploy.master.Master

  spark-worker:
    image: bitnami/spark:latest
    depends_on:
      - spark
      - kafka
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=1g
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark:7077

  spark-job:
    build: ./spark_stream
    depends_on:
      - spark
      - kafka
    environment:
      - SPARK_MODE=client
      - SPARK_MASTER_URL=spark://spark:7077
    command: ["python", "spark_stream.py"]

  kafka-producer:
    build: ./kafka_producer
    depends_on:
      - kafka
    environment:
      - KAFKA_BROKER_URL=kafka:9092
    command: ["python", "kafka_producer.py"]

networks:
  default:
    driver: bridge


# etl\resources\docker-compose.yaml